{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "com2028coursework.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLgSiokpOF4o",
        "colab_type": "code",
        "outputId": "83b8c850-6801-47ac-f525-dfb984a2edba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTDgVYvfKt5i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "f1c76a00-d83a-472f-b596-941cd8715431"
      },
      "source": [
        "! pip install scipy==1.1.0\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 141kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.18.4)\n",
            "\u001b[31mERROR: umap-learn 0.4.3 has requirement scipy>=1.3.1, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed scipy-1.1.0\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BflHaKZrAEhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import tensorflow as tf\n",
        "from scipy.misc import imread, imsave\n",
        "from skimage.segmentation import clear_border\n",
        "from skimage.morphology import label\n",
        "from skimage.measure import regionprops\n",
        "from skimage.transform import resize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP7zmM-gIpT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Extract_Letters:\n",
        "    def extractFile(self, filename):\n",
        "        image = imread(filename, 1)\n",
        "    \n",
        "        #apply threshold in order to make the image binary\n",
        "        bw = image < 120\n",
        "    \n",
        "        # remove artifacts connected to image border\n",
        "        cleared = bw.copy()\n",
        "        #clear_border(cleared)\n",
        "\n",
        "        # label image regions\n",
        "        label_image = label(cleared,neighbors=8)\n",
        "        borders = np.logical_xor(bw, cleared)\n",
        "        label_image[borders] = -1\n",
        "    \n",
        "    \n",
        "        #fig = plt.figure(figsize=(6,6))\n",
        "        #ax = fig.add_subplot(131)\n",
        "        #ax.imshow(bw, cmap='jet')\n",
        "\n",
        "        letters = list()\n",
        "        order = list()\n",
        "    \n",
        "        for region in regionprops(label_image):\n",
        "            minc, minr, maxc, maxr = region.bbox\n",
        "            # skip small images\n",
        "            if maxc - minc > len(image)/250: # better to use height rather than area.\n",
        "                rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr, fill=False, edgecolor='red', linewidth=2)\n",
        "                order.append(region.bbox)\n",
        "\n",
        "\n",
        "        #sort the detected characters left->right, top->bottom\n",
        "        lines = list()\n",
        "        first_in_line = ''\n",
        "        counter = 0\n",
        "\n",
        "        #worst case scenario there can be 1 character per line\n",
        "        for x in range(len(order)):\n",
        "            lines.append([])\n",
        "    \n",
        "        for character in order:\n",
        "            if first_in_line == '':\n",
        "                first_in_line = character\n",
        "                lines[counter].append(character)\n",
        "            elif abs(character[0] - first_in_line[0]) < (first_in_line[2] - first_in_line[0]):\n",
        "                lines[counter].append(character)\n",
        "            elif abs(character[0] - first_in_line[0]) > (first_in_line[2] - first_in_line[0]):\n",
        "                first_in_line = character\n",
        "                counter += 1\n",
        "                lines[counter].append(character)\n",
        "\n",
        "\n",
        "        for x in range(len(lines)):       \n",
        "            lines[x].sort(key=lambda tup: tup[1])\n",
        "\n",
        "        final = list()\n",
        "        prev_tr = 0\n",
        "        prev_line_br = 0\n",
        "        \n",
        "        for i in range(len(lines)):\n",
        "            for j in range(len(lines[i])):\n",
        "                tl_2 = lines[i][j][1]\n",
        "                bl_2 = lines[i][j][0]\n",
        "                if tl_2 > prev_tr and bl_2 > prev_line_br:\n",
        "                    tl,tr,bl,br = lines[i][j]\n",
        "                    letter_raw = bw[tl:bl,tr:br]\n",
        "                    letter_norm = resize(letter_raw ,(20 ,20))\n",
        "                    final.append(letter_norm)\n",
        "                    prev_tr = lines[i][j][3]\n",
        "                if j == (len(lines[i])-1):\n",
        "                    prev_line_br = lines[i][j][2]\n",
        "            prev_tr = 0\n",
        "            tl_2 = 0\n",
        "\n",
        "        print (\"Characters recognized: \" + str(len(final)))\n",
        "        return final\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        print (\"Extracting characters...\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKhn1TWsWMbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=123):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1ANgTOzO2sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_inputs = 20*20 #size of box around letter\n",
        "n_hidden1 = 52\n",
        "n_outputs = 26 #number of different characters\n",
        "learning_rate = 0.05"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUGrW6KzR7hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int32, shape=(None), name=\"y\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKbbPMsCSRLz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "58556152-9355-4fef-aedb-2bab8ea88bc1"
      },
      "source": [
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
        "    logits = tf.layers.dense(hidden1, n_outputs, name=\"outputs\")\n",
        "    y_proba = tf.nn.softmax(logits)\n",
        "\n",
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "\n",
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    training_op = optimizer.minimize(loss)\n",
        "\n",
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-3ef1631b5188>:2: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VhbRX2e93p-",
        "colab_type": "code",
        "outputId": "77f1eb4e-c595-48fb-d21c-514227f248f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "start_time = time.time()\n",
        "extract = Extract_Letters()\n",
        "training_files = ['./gdrive/My Drive/COM2028_Coursework/Training_Data/A.png', './gdrive/My Drive/COM2028_Coursework/Training_Data/B.png', \n",
        "                  './gdrive/My Drive/COM2028_Coursework/Training_Data/C.png', './gdrive/My Drive/COM2028_Coursework/Training_Data/D.png', \n",
        "\t\t\t\t\t\t\t\t\t'./gdrive/My Drive/COM2028_Coursework/Training_Data/E.png', './gdrive/My Drive/COM2028_Coursework/Training_Data/F.png', \n",
        "\t\t\t\t\t\t\t\t\t'./gdrive/My Drive/COM2028_Coursework/Training_Data/G.png', './gdrive/My Drive/COM2028_Coursework/Training_Data/H.png', \n",
        "\t\t\t\t\t\t\t\t\t'./gdrive/My Drive/COM2028_Coursework/Training_Data/I.png', './gdrive/My Drive/COM2028_Coursework/Training_Data/J.png', \n",
        "\t\t\t\t\t\t\t\t\t'./gdrive/My Drive/COM2028_Coursework/Training_Data/K.png', './gdrive/My Drive/COM2028_Coursework/Training_Data/L.png', \n",
        "\t\t\t\t\t\t\t\t\t'./gdrive/My Drive/COM2028_Coursework/Training_Data/M.png', './gdrive/My Drive/COM2028_Coursework/Training_Data/N.png', \n",
        "\t\t\t\t\t\t\t\t\t'./gdrive/My Drive/COM2028_Coursework/Training_Data/O.png', './gdrive/My Drive/COM2028_Coursework/Training_Data/P.png', \n",
        "\t\t\t\t\t\t\t\t\t'./gdrive/My Drive/COM2028_Coursework/Training_Data/Q.png', './gdrive/My Drive/COM2028_Coursework/Training_Data/R.png', \n",
        "\t\t\t\t\t\t\t\t\t'./gdrive/My Drive/COM2028_Coursework/Training_Data/S.png', './gdrive/My Drive/COM2028_Coursework/Training_Data/T.png',\n",
        "\t\t\t\t\t\t\t\t\t'./gdrive/My Drive/COM2028_Coursework/Training_Data/U.png', './gdrive/My Drive/COM2028_Coursework/Training_Data/V.png',\n",
        "\t\t\t\t\t\t\t\t\t'./gdrive/My Drive/COM2028_Coursework/Training_Data/W.png', './gdrive/My Drive/COM2028_Coursework/Training_Data/X.png', \n",
        "\t\t\t\t\t\t\t\t\t'./gdrive/My Drive/COM2028_Coursework/Training_Data/Y.png', './gdrive/My Drive/COM2028_Coursework/Training_Data/Z.png']\n",
        "\n",
        "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
        "count = 0\n",
        "\n",
        "X_train = None\n",
        "X_valid = None\n",
        "y_train = None\n",
        "y_valid = None\n",
        "\n",
        "for files in training_files:\n",
        "\tletters = extract.extractFile(files)\n",
        " \n",
        "\tvalues = np.array(letters)\n",
        "\tvalues = values.astype(np.float32).reshape(-1, 20*20)\n",
        "\tvalid_values, train_values = values[:20], values[20:]\n",
        "\tlabels = np.full(len(letters), count)\n",
        "\tvalid_labels, train_labels = labels[:20], labels[20:]\n",
        "\n",
        "\tif count == 0:\n",
        "\t\tX_train = train_values\n",
        "\t\ty_train = train_labels\n",
        "\t\tX_valid = valid_values\n",
        "\t\ty_valid = valid_labels\n",
        "\telse:\n",
        "\t\tX_train = np.concatenate((X_train, train_values))\n",
        "\t\ty_train = np.concatenate((y_train, train_labels))\n",
        "\t\tX_valid = np.concatenate((X_valid, valid_values))\n",
        "\t\ty_valid = np.concatenate((y_valid, valid_labels))\n",
        "\n",
        "\tcount += 1\n",
        " \n",
        "print(time.time() - start_time, \"seconds\" )\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting characters...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The argument 'neighbors' is deprecated and will be removed in scikit-image 0.18, use 'connectivity' instead. For neighbors=8, use connectivity=2\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Characters recognized: 643\n",
            "Characters recognized: 668\n",
            "Characters recognized: 672\n",
            "Characters recognized: 671\n",
            "Characters recognized: 696\n",
            "Characters recognized: 821\n",
            "Characters recognized: 650\n",
            "Characters recognized: 667\n",
            "Characters recognized: 1029\n",
            "Characters recognized: 954\n",
            "Characters recognized: 670\n",
            "Characters recognized: 879\n",
            "Characters recognized: 540\n",
            "Characters recognized: 622\n",
            "Characters recognized: 670\n",
            "Characters recognized: 701\n",
            "Characters recognized: 677\n",
            "Characters recognized: 724\n",
            "Characters recognized: 726\n",
            "Characters recognized: 798\n",
            "Characters recognized: 660\n",
            "Characters recognized: 672\n",
            "Characters recognized: 517\n",
            "Characters recognized: 639\n",
            "Characters recognized: 669\n",
            "Characters recognized: 719\n",
            "27.683340549468994 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHc3FapFORHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 20\n",
        "batch_size = 500"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUMeEs5A6w32",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "e2d7f66c-c05a-4b7f-96dd-e8ca8d95d00b"
      },
      "source": [
        "def shuffle_batch(X, y, batch_size):\n",
        "    rnd_idx = np.random.permutation(len(X))\n",
        "    n_batches = len(X) // batch_size\n",
        "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
        "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
        "        yield X_batch, y_batch\n",
        "        \n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
        "        print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
        "\n",
        "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Batch accuracy: 0.35952848 Validation accuracy: 0.4\n",
            "1 Batch accuracy: 0.6208252 Validation accuracy: 0.74423075\n",
            "2 Batch accuracy: 0.69155204 Validation accuracy: 0.8384615\n",
            "3 Batch accuracy: 0.697446 Validation accuracy: 0.875\n",
            "4 Batch accuracy: 0.73477405 Validation accuracy: 0.89807695\n",
            "5 Batch accuracy: 0.7721022 Validation accuracy: 0.9307692\n",
            "6 Batch accuracy: 0.7426326 Validation accuracy: 0.95\n",
            "7 Batch accuracy: 0.75442046 Validation accuracy: 0.9653846\n",
            "8 Batch accuracy: 0.7426326 Validation accuracy: 0.97884613\n",
            "9 Batch accuracy: 0.78781927 Validation accuracy: 0.98846155\n",
            "10 Batch accuracy: 0.7976424 Validation accuracy: 0.99038464\n",
            "11 Batch accuracy: 0.78389 Validation accuracy: 0.98653847\n",
            "12 Batch accuracy: 0.8015717 Validation accuracy: 0.99423075\n",
            "13 Batch accuracy: 0.80943024 Validation accuracy: 0.99423075\n",
            "14 Batch accuracy: 0.81925344 Validation accuracy: 0.99423075\n",
            "15 Batch accuracy: 0.8310413 Validation accuracy: 0.99423075\n",
            "16 Batch accuracy: 0.84675837 Validation accuracy: 0.99423075\n",
            "17 Batch accuracy: 0.84479374 Validation accuracy: 0.98846155\n",
            "18 Batch accuracy: 0.8231827 Validation accuracy: 0.99423075\n",
            "19 Batch accuracy: 0.84282905 Validation accuracy: 0.99038464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8IBdORV5HUB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "4fd2096a-9454-4425-cf71-c6fb16b9ead2"
      },
      "source": [
        "letters = extract.extractFile('./gdrive/My Drive/COM2028_Coursework/Testing_Data/test_normal.png')\n",
        " \n",
        "X_test = np.array(letters)\n",
        "X_test = X_test.astype(np.float32).reshape(-1, 20*20)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Characters recognized: 72\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: The argument 'neighbors' is deprecated and will be removed in scikit-image 0.18, use 'connectivity' instead. For neighbors=8, use connectivity=2\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYKKD9yPR4HT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "dd38f43b-ef21-4330-b521-bdcc6444d385"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
        "    X_new_scaled = X_test\n",
        "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
        "    y_pred = np.argmax(Z, axis=1)\n",
        "    print(\"Predicted letters: [\", end = \"\" )\n",
        "    for pred in y_pred:\n",
        "      print(alphabet[pred] + \" \", end = \"\")\n",
        "    print(\"]\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
            "Predicted letters: [t h g g r g a t g s t g i o r y i a i i g i n g i i g s n o t i n n g g g r f a i i i n g j g u t i n g l s o g c g v g g y t o g e w g f a i i ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c0awvMD6-Ei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}